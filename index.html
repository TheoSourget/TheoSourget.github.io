<!doctype html><html lang=en><head><meta name=generator content="Hugo 0.128.0"><title>Theo Sourget</title>
<meta name=description content="Portfolio and personal blog of Théo Sourget."><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=stylesheet href=/application.5b7777e57c70f92a6339db87ad8b77d43266b3f01b9b591a1fac1f495003fb3c.css integrity="sha256-W3d35Xxw+SpjOduHrYt31DJms/Abm1kaH6wfSVAD+zw="><link rel=icon type=image/png href=/images/site/favicon_hufc4bafdc671c7057b1ecde31fbd405de_7745_42x0_resize_box_3.png><meta property="og:title" content="Théo Sourget site"><meta property="og:type" content="website"><meta property="og:description" content="Portfolio and personal blog of Théo sourget."><meta property="og:image" content="/images/author/theo_sourget.jpg"><meta property="og:url" content="https://hugo-toha.github.io"><meta name=twitter:card content="summary"><meta name=twitter:title content="Theo Sourget"></head><body data-spy=scroll data-target=#top-navbar data-offset=100><nav class="navbar navbar-expand-xl top-navbar initial-navbar" id=top-navbar><div class=container><a class=navbar-brand href=/><img src=/images/site/inverted-logo_hufc4bafdc671c7057b1ecde31fbd405de_7745_42x0_resize_box_3.png id=logo alt=Logo>
Theo Sourget</a>
<button class="navbar-toggler navbar-dark" id=navbar-toggler type=button data-toggle=collapse data-target=#top-nav-items aria-label=menu>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse dynamic-navbar" id=top-nav-items><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=#home>Home</a></li><li class=nav-item><a class=nav-link href=#about>About</a></li><li class=nav-item><a class=nav-link href=#skills>Skills</a></li><li class=nav-item><a class=nav-link href=#experiences>Experiences</a></li><li class=nav-item><a class=nav-link href=#education>Education</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>More</a><div class=dropdown-menu aria-labelledby=navbarDropdown><a class=dropdown-item href=#projects>Projects</a>
<a class=dropdown-item href=#publications>Publications</a>
<a class=dropdown-item href=#recent-posts>Recent Posts</a></div></li><div class=dropdown-divider id=top-navbar-divider></div><li class=nav-item><a class=nav-link id=blog-link href=/posts/>Posts</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=languageSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><span class="flag-icon flag-icon-gb"></span>
English</a><div class=dropdown-menu aria-labelledby=languageSelector><a class="dropdown-item nav-link languages-item" href=/><span class="flag-icon flag-icon-gb"></span>
English
</a><a class="dropdown-item nav-link languages-item" href=/fr/><span class="flag-icon flag-icon-fr"></span>
Français</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme"></a><div id=themeMenu class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# data-scheme=light><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20 alt="Light Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=dark><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=system><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20 alt="System Theme"></a></div></li></ul></div></div><img src=/images/site/main-logo_hu01b04d9b15708a71e9c2309188ef8c64_5961_42x0_resize_box_3.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hufc4bafdc671c7057b1ecde31fbd405de_7745_42x0_resize_box_3.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><div class="container-fluid home" id=home><style>#homePageBackgroundImageDivStyled{background-image:url(/images/site/background_hu7849b20ce9ad2599a2189d7278ab15e2_507703_500x0_resize_q75_box.jpg)}@media(min-width:500px) and (max-width:800px){#homePageBackgroundImageDivStyled{background-image:url(/images/site/background_hu7849b20ce9ad2599a2189d7278ab15e2_507703_800x0_resize_q75_box.jpg)}}@media(min-width:801px) and (max-width:1200px){#homePageBackgroundImageDivStyled{background-image:url(/images/site/background_hu7849b20ce9ad2599a2189d7278ab15e2_507703_1200x0_resize_q75_box.jpg)}}@media(min-width:1201px) and (max-width:1500px){#homePageBackgroundImageDivStyled{background-image:url(/images/site/background_hu7849b20ce9ad2599a2189d7278ab15e2_507703_1500x0_resize_q75_box.jpg)}}@media(min-width:1501px){#homePageBackgroundImageDivStyled{background-image:url(/images/site/background.jpg)}}</style><span class=on-the-fly-behavior></span><div id=homePageBackgroundImageDivStyled class="background container-fluid"></div><div class="container content text-center"><img src=/images/author/theo_s_hud178ec81fa2deea35dffcf6f904db8d9_21189_148x148_fit_q75_box.jpeg class="rounded-circle mx-auto d-block img-fluid" alt="Author Image"><h1 class=greeting>Hi, I am Théo Sourget</h1><div class=typing-carousel><span id=ityped class=ityped></span>
<span class=ityped-cursor></span></div><ul id=typing-carousel-data><li>I am a Data Scientist</li><li>I am a Research Assistant</li><li>I am interested in Medical Image Analysis</li></ul><a href=#about class=arrow-center aria-label="Read More - Théo Sourget"><i class="arrow bounce fa fa-chevron-down"></i></a></div></div><div class="container-fluid section-holder d-flex bg-white"><div class="container anchor p-lg-5 about-section" id=about><div class="row pt-sm-2 pt-md-4 align-self-center"><div class=col-sm-12><h3 class=p-1>Théo Sourget</h3><h5 class=p-1>Research Assistant
at <a href=https://purrlab.github.io/ title="IT University of Copenhagen - PURRlab." target=_blank rel=noopener>IT University of Copenhagen - PURRlab.</a></h5><p class="p-1 text-justify">Passionate about Data Science and AI, I graduated in 2023 with a Master&rsquo;s degree in Data Science at the <a href=http://mastersid.univ-rouen.fr/en/index.php target=_blank rel=noopener>Université de Rouen</a>. During my studies I&rsquo;ve specialised myself in Medical Image Analysis with projects focusing on the classification and segmentation of medical images using deep learning models. These projects were also about training transformer models with small datasets and the effect of Data Augmentation and Transfer learning. I&rsquo;m currently a Research Assistant of the <a href=https://purrlab.github.io/ target=_blank rel=noopener>PURRlab</a> at the IT University of Copenhagen. My research areas are the robustness of AI in healthcare and the study of public medical datasets in research papers.</p><div class="text-container ml-auto"><ul class="social-link d-flex"><li><a href=https://github.com/TheoSourget title=Github target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/theo-sourget/ title=LinkedIn target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=mailto:tsou@itu.dk title=Email target=_blank rel=noopener><i class="fas fa-envelope"></i></a></li></ul></div><a href=/files/resume.pdf title="My Resume" target=#><button class="btn btn-dark">My Resume</button></a></div><div class="col-sm-6 pt-5 pl-md-4 pl-sm-3 pt-sm-0"><div class=row></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-dimmed"><div class="container-fluid anchor pb-5 skills-section"><h1 class=text-center><span id=skills></span>Skills</h1><div class="container d-flex-block"><div class=row id=primary-skills><div class="col-xs-12 col-sm-6 col-lg-4 pt-2"><a class=skill-card-link><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/python_hu89fabe49305bb37a014afc610b72638e_100734_24x24_fit_box_3.png alt=Python><h5 class=card-title>Python</h5></div><div class=card-body><p class=card-text>Python is the language I use the most. I&rsquo;ve used many libraries for Data Science such as PyTorch, Pandas, scikit-learn and numpy.</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2"><a class=skill-card-link><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/streamlit.svg alt=Streamlit><h5 class=card-title>Streamlit</h5></div><div class=card-body><p class=card-text>I created multiple tools with Streamlit to showcase my work or to make open access tools.</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2"><a class=skill-card-link><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/api_hu20797a8507ab28158bdcda3f14083fee_12042_24x24_fit_box_3.png alt=API><h5 class=card-title>API</h5></div><div class=card-body><p class=card-text>I&rsquo;ve worked with APIs on a number of projects and used FastAPI to create my own APIs.</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2"><a class=skill-card-link><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/docker.svg alt=Docker><h5 class=card-title>Docker</h5></div><div class=card-body><p class=card-text>I&rsquo;ve used Docker in multiple projects especially in combination with Streamlit and FastAPI to ease the deployment of models or tools.</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2"><a class=skill-card-link><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/linux_huf8888e89df43f58ab32b560cb211e230_26357_24x24_fit_box_3.png alt=Linux><h5 class=card-title>Linux</h5></div><div class=card-body><p class=card-text>I&rsquo;ve been using Linux as my main operating system for 4 years.</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2"><a class=skill-card-link><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/git_hu6c1226675924c2f2e3476a81b4d03976_10660_24x24_fit_box_3.png alt=Git><h5 class=card-title>Git</h5></div><div class=card-body><p class=card-text>I&rsquo;m experienced with git-based development. I&rsquo;ve used both Github and Gitlab.</p></div></div></a></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-white"><div class="container-fluid anchor pb-5 experiences-section"><h1 class=text-center><span id=experiences></span>Experiences</h1><div class="container timeline text-justify"><div class="row align-items-center d-flex"><div class="col-1 col-lg-2 text-center vertical-line d-inline-flex justify-content-center"><div class="circle font-weight-bold">1</div></div><div class="col-10 col-lg-8"><div class=experience-entry-heading><h5><a href=https://purrlab.github.io/ title="IT University of Copenhagen - PURRlab" target=_blank rel=noopener>IT University of Copenhagen - PURRlab</a></h5><p class=text-muted>October 2023 - January 2025,
Copenhagen (Denmark)</p><p></p></div><div class=positions><h6 class=designation>Research Assistant</h6><p class=text-muted>October 2023 - January 2025</p><ul class=justify-content-around><li>Study the usage of non-relevant information (e.g. background) in chest X-ray images by CNN models</li><li>Studied how public medical image datasets are referenced in research papers</li></ul><h6 class=designation>Assistant Lecturer</h6><p class=text-muted>January 2024 - July 2024</p><ul class=justify-content-around><li>Prepared and teach lectures to bachelor&rsquo;s students of the Project in Data Science course (Git, decision trees, ensemble of classifiers, common problems in machine learning projects)</li><li>Prepared exercises sessions</li></ul><h6 class=designation>Teaching Assistant</h6><p class=text-muted>October 2023 - Dec 2023</p><ul class=justify-content-around><li>Helped students during practical work of the Data In the Wild Course (data processing, visualisation, web scraping)</li><li>Assisted teachers in the preparation of the exercises</li></ul></div></div></div><div class="row horizontal-line"><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div><div class="col-10 col-lg-8"><hr></div><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div></div><div class="row align-items-center justify-content-end d-flex"><div class="col-10 col-lg-8"><div class=experience-entry-heading><h5>Data scientist intern</h5><h6><a href=https://www.capgemini.com/us-en/about-us/who-we-are/our-brands/capgemini-engineering/ title="Capgemini Engineering - Medic@" target=_blank rel=noopener>Capgemini Engineering - Medic@</a></h6><p class=text-muted>April 2023 - September 2023,
Illkirch-Graffenstaden (France)</p></div><p></p><h6 class=text-muted>Responsibilities:</h6><ul class=justify-content-around><li>Detection, segmentation and numbering of teeth in dental panoramic x-ray.</li><li>Comparison of Mask-RCNN and Detection Transformer (DETR).</li><li>Comparison of &ldquo;classical&rdquo; data augmentation technics with augmentation using the generation of new panoramics.</li></ul></div><div class="col-1 col-lg-2 text-center vertical-line d-inline-flex justify-content-center"><div class="circle font-weight-bold">2</div></div></div><div class="row horizontal-line"><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div><div class="col-10 col-lg-8"><hr></div><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div></div><div class="row align-items-center d-flex"><div class="col-1 col-lg-2 text-center vertical-line d-inline-flex justify-content-center"><div class="circle font-weight-bold">3</div></div><div class="col-10 col-lg-8"><div class=experience-entry-heading><h5><a href=https://see-d.fr/ title=See-d target=_blank rel=noopener>See-d</a></h5><p class=text-muted>April 2021 - July 2021,
Vannes (France)</p><p></p></div><div class=positions><h6 class=designation>Developer</h6><p class=text-muted>June 2021 - July 2021</p><ul class=justify-content-around><li>Continuation of the intership</li><li>Creation of a dashboard with Qlik Sense using the previously created API</li></ul><h6 class=designation>Developer Intern</h6><p class=text-muted>April 2021 - June 2021</p><ul class=justify-content-around><li>Development of a storage-related data analysis website with Python and Streamlit</li><li>Deployement with Docker</li><li>Presentation of the tool to the team</li></ul></div></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-dimmed"><div class="container-fluid anchor pb-5 education-section"><h1 class=text-center><span id=education></span>Education</h1><div class=container><table class=education-info-table><tbody><tr><td class=icon><div class=hline></div><div class=icon-holder><i class="fas fa-graduation-cap"></i></div></td><td class=line><div></div></td><td class=details><div class="degree-info card"><div class=row><div class="col-lg-10 col-md-8"><h5><a href=http://mastersid.univ-rouen.fr/en/index.php title="Université de Rouen" target=_blank rel=noopener>Université de Rouen</a></h5></div><div class="timeframe col-lg-2 col-md-4">2021-2023</div></div><h6>Master Data Science and Engineering (SID)</h6><h6><span class=text-muted>Grade: </span><span>16.215</span> out of <span>20 (Valedictorian, Graduated with Highest Honors)</span></h6></div></td></tr><tr><td class=icon><div class=hline></div><div class=icon-holder><i class="fas fa-university"></i></div></td><td class=line><div></div></td><td class=details><div class="degree-info card"><div class=row><div class="col-lg-10 col-md-8"><h5>Université de Rouen</h5></div><div class="timeframe col-lg-2 col-md-4">2020-2021</div></div><h6>Bachelor's degree in Computer Science and Data Science</h6><h6><span class=text-muted>Grade: </span><span>14.958</span> out of <span>20 (Valedictorian, Graduated with Honors)</span></h6></div></td></tr><tr><td class=icon><div class=hline></div><div class=icon-holder><i class="fas fa-university"></i></div></td><td class=line><div></div></td><td class=details><div class="degree-info card"><div class=row><div class="col-lg-10 col-md-8"><h5>IUT de Vannes</h5></div><div class="timeframe col-lg-2 col-md-4">2018-2020</div></div><h6>2 years diploma in Computer science</h6><h6><span class=text-muted>Grade: </span><span>13.835</span> out of <span>20</span></h6></div></td></tr></tbody></table></div></div></div><div class="container-fluid section-holder d-flex bg-white"><div class="container-fluid anchor pb-5 projects-section" id=projects><h1 class=text-center><span id=projects></span>Projects</h1><div class="container ml-auto text-center"><div class="btn-group flex-wrap" role=group id=project-filter-buttons><button type=button class="btn btn-dark project-filtr-control" data-filter=all>
All
</button>
<button type=button class="btn btn-dark project-filtr-control" data-filter="Medical Image Analysis">
Medical Image Analysis
</button>
<button type=button class="btn btn-dark project-filtr-control" data-filter=Sport>
Sport
</button>
<button type=button class="btn btn-dark project-filtr-control" data-filter=Web>
Web</button></div></div><div class="container filtr-projects"><div class=row id=project-card-holder><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Medical Image Analysis,Shortcut learning,CNN'><div class="card mt-1"><div class=card><a class=card-header href=https://github.com/TheoSourget/MMC_Masking target=_blank rel=noopener><div><div class=d-flex><h5 class="card-title mb-0">Mask of truth</h5></div><div class=sub-title><span></span>
<span>2024</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Pipeline to study the ability of a CNN model to classify images without the region of interest in medical images and evaluate potential bias/shortcuts in datasets</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Medical Image Analysis
</span><span class="badge btn-info">Shortcut learning
</span><span class="badge btn-info">CNN</span></div><div class=project-btn-holder><a class="github-button project-btn d-none" href=https://github.com/TheoSourget/MMC_Masking data-icon=octicon-standard data-show-count=true aria-label="Star Mask of truth">Star</a></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Dataset Tracking,API,Scraping'><div class="card mt-1"><div class=card><a class=card-header href=https://github.com/TheoSourget/Public_Medical_Datasets_References target=_blank rel=noopener><div><div class=d-flex><h5 class="card-title mb-0">Citation needed</h5></div><div class=sub-title><span></span>
<span>2024</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Pipeline to detect dataset presence in research papers</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Dataset Tracking
</span><span class="badge btn-info">API
</span><span class="badge btn-info">Scraping</span></div><div class=project-btn-holder><a class="github-button project-btn d-none" href=https://github.com/TheoSourget/Public_Medical_Datasets_References data-icon=octicon-standard data-show-count=true aria-label="Star Citation needed">Star</a></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Web,PDF,Streamlit,Annotation Tool,Docker'><div class="card mt-1"><div class=card><a class=card-header href=https://github.com/TheoSourget/pdf_annotator target=_blank rel=noopener><div><div class=d-flex><h5 class="card-title mb-0">PDF Annotator</h5></div><div class=sub-title><span></span>
<span>2024</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Web APP to annotate PDF File. The files can be annotate by multiple users for up to two initial sets of labels.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Web
</span><span class="badge btn-info">PDF
</span><span class="badge btn-info">Streamlit
</span><span class="badge btn-info">Annotation Tool
</span><span class="badge btn-info">Docker</span></div><div class=project-btn-holder><a class="github-button project-btn d-none" href=https://github.com/TheoSourget/pdf_annotator data-icon=octicon-standard data-show-count=true aria-label="Star PDF Annotator">Star</a></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Web,API,Streamlit,FastAPI,Docker'><div class="card mt-1"><div class=card><a class=card-header href=https://github.com/TheoSourget/citation_finder target=_blank rel=noopener><div><div class=d-flex><h5 class="card-title mb-0">Citation finder</h5></div><div class=sub-title><span></span>
<span>2023</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Website multiple API such as OpenAlex to search for papers referencing another one and papers matching keywords and concept.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Web
</span><span class="badge btn-info">API
</span><span class="badge btn-info">Streamlit
</span><span class="badge btn-info">FastAPI
</span><span class="badge btn-info">Docker</span></div><div class=project-btn-holder><a class="github-button project-btn d-none" href=https://github.com/TheoSourget/citation_finder data-icon=octicon-standard data-show-count=true aria-label="Star Citation finder">Star</a></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Medical Image Analysis,Segmentation,Transformer,Pytorch'><div class="card mt-1"><div class=card><a class=card-header href=https://github.com/TheoSourget/SegFormer_CAMUS target=_blank rel=noopener><div><div class=d-flex><h5 class="card-title mb-0">Comparaison of UNet and SegFormer for medical image segmentation (Master 2 project)</h5></div><div class=sub-title><span></span>
<span>2022 - 2023</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Comparison of Segformer and U-Net to perform semantic segmentation on the CAMUS dataset (cardiac ultrasound images).</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Medical Image Analysis
</span><span class="badge btn-info">Segmentation
</span><span class="badge btn-info">Transformer
</span><span class="badge btn-info">Pytorch</span></div><div class=project-btn-holder><a class="github-button project-btn d-none" href=https://github.com/TheoSourget/SegFormer_CAMUS data-icon=octicon-standard data-show-count=true aria-label="Star Comparaison of UNet and SegFormer for medical image segmentation (Master 2 project)">Star</a></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Medical Image Analysis,Classification,Tensorflow,CNN'><div class="card mt-1"><div class=card><a class=card-header href=javascript:void(0)><div><div class=d-flex><h5 class="card-title mb-0">Glaucoma Detection with CNN (Master 1 project)</h5></div><div class=sub-title><span></span>
<span>2021 - 2022</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Classification of eye fundus images for glaucoma detection with convolutional neural network.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Medical Image Analysis
</span><span class="badge btn-info">Classification
</span><span class="badge btn-info">Tensorflow
</span><span class="badge btn-info">CNN</span></div><div class=project-btn-holder></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Data Analysis,Sport,Matplotlib,Pandas'><div class="card mt-1"><div class=card><a class=card-header href=javascript:void(0)><div><div class=d-flex><h5 class="card-title mb-0">Bachelor's degree project</h5></div><div class=sub-title><span></span>
<span>2020 - 2021</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Analysis of a dataset on the 2011-2012 season of the Premier League.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Data Analysis
</span><span class="badge btn-info">Sport
</span><span class="badge btn-info">Matplotlib
</span><span class="badge btn-info">Pandas</span></div><div class=project-btn-holder></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Web,React,Flask,MongoDB'><div class="card mt-1"><div class=card><a class=card-header href=javascript:void(0)><div><div class=d-flex><h5 class="card-title mb-0">Astronomical observation website</h5></div><div class=sub-title><span></span>
<span>2020</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Development of an astronomical observation website with React-Flask-MongoDB.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Web
</span><span class="badge btn-info">React
</span><span class="badge btn-info">Flask
</span><span class="badge btn-info">MongoDB</span></div><div class=project-btn-holder></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Web,Mobile,Sport,React,MERN stack'><div class="card mt-1"><div class=card><a class=card-header href=javascript:void(0)><div><div class=d-flex><h5 class="card-title mb-0">Applicharge</h5></div><div class=sub-title><span></span>
<span>2019-2020</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Development of a website and a mobile application for sports management with React/React Native.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Web
</span><span class="badge btn-info">Mobile
</span><span class="badge btn-info">Sport
</span><span class="badge btn-info">React
</span><span class="badge btn-info">MERN stack</span></div><div class=project-btn-holder></div></div></div></div></div></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-dimmed"><div class="container-fluid anchor pb-5 publications-section" id=publications><h1 class=text-center><span id=publications></span>Publications</h1><div class="container ml-auto text-center"><div class="btn-group flex-wrap" role=pub-group id=publication-filter-buttons></div></div><div class="container filtr-publications"><div class=row id=publication-card-holder><div class="col-12 p-2 pub-filtr-item" data-category=pub-all,pub-machinelearning,pub-medical><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Copycats: the many lives of a publicly available medical imaging dataset</h5><div class=sub-title><span><a href=https://neurips.cc/>NeurIPS 2024 Datasets and Benchmarks Track</a></span>
<span class=ml-2>December 2024</span></div><div class=authors><span class=mr-2><a href>Amelia Jiménez-Sánchez</a></span>
<span class=mr-2><a href>Natalia-Rozalia Avlona</a></span>
<span class=mr-2><a href>Dovile Juodelyte</a></span>
<span class=mr-2><a href>Théo Sourget</a></span>
<span class=mr-2><a href>Caroline Vang-Larsen</a></span>
<span class=mr-2><a href>Anna Rogers</a></span>
<span class=mr-2><a href>Hubert Dariusz Zajac</a></span>
<span class=mr-2><a href>Veronika Cheplygina</a></span></div></div><div class=card-body><p>Medical Imaging (MI) datasets are fundamental to artificial intelligence in healthcare. The accuracy, robustness, and fairness of diagnostic algorithms depend on the data (and its quality) used to train and evaluate the models. MI datasets used to be proprietary, but have become increasingly available to the public, including on community-contributed platforms (CCPs) like Kaggle or HuggingFace. While open data is important to enhance the redistribution of data&rsquo;s public value, we find that the current CCP governance model fails to uphold the quality needed and recommended practices for sharing, documenting, and evaluating datasets. In this paper, we conduct an analysis of publicly available machine learning datasets on CCPs, discussing datasets&rsquo; context, and identifying limitations and gaps in the current CCP landscape. We highlight differences between MI and computer vision datasets, particularly in the potentially harmful downstream effects from poor adoption of recommended dataset management practices. We compare the analyzed datasets across several dimensions, including data sharing, data documentation, and maintenance. We find vague licenses, lack of persistent identifiers and storage, duplicates, and missing metadata, with differences between the platforms. Our research contributes to efforts in responsible data curation and AI algorithms for healthcare.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ml-1 p-2">Open Data
</span><span class="btn badge btn-info ml-1 p-2">Medical Imaging
</span><span class="btn badge btn-info ml-1 p-2">Datasets
</span><span class="btn badge btn-info ml-1 p-2">Dataset Management
</span><span class="btn badge btn-info ml-1 p-2">Data Governance</span></div><div class=details-btn><a class="btn btn-outline-info ml-1 pl-2 mb-2" href=https://arxiv.org/abs/2402.06353 target=_blank rel=noopener role=button>Details</a></div></div></div></div><div class="col-12 p-2 pub-filtr-item" data-category=pub-all,pub-machinelearning,pub-medical><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">[Citation needed] Data usage and citation practices in medical imaging conferences</h5><div class=sub-title><span><a href=https://2024.midl.io/>Medical Imaging with Deep Learning 2024 (MIDL'24)</a></span>
<span class=ml-2>July 2024</span></div><div class=authors><span class=mr-2><a href=https://tsourget.fr>Théo Sourget</a></span>
<span class=mr-2><a href>Ahmet Akkoç</a></span>
<span class=mr-2><a href>Stinna Winther</a></span>
<span class=mr-2><a href>Christine Lyngbye Galsgaard</a></span>
<span class=mr-2><a href>Amelia Jiménez-Sánchez</a></span>
<span class=mr-2><a href>Dovile Juodelyte</a></span>
<span class=mr-2><a href>Caroline Petitjean</a></span>
<span class=mr-2><a href>Veronika Cheplygina</a></span></div></div><div class=card-body><p>Medical imaging papers often focus on methodology, but the quality of the algorithms and the validity of the conclusions are highly dependent on the datasets used. As creating datasets requires a lot of effort, researchers often use publicly available datasets, there is however no adopted standard for citing the datasets used in scientific papers, leading to difficulty in tracking dataset usage. In this work, we present two open-source tools we created that could help with the detection of dataset usage, a pipeline using OpenAlex and full-text analysis, and a PDF annotation software used in our study to manually label the presence of datasets. We applied both tools on a study of the usage of 20 publicly available medical datasets in papers from MICCAI and MIDL. We compute the proportion and the evolution between 2013 and 2023 of 3 types of presence in a paper: cited, mentioned in the full text, cited and mentioned. Our findings demonstrate the concentration of the usage of a limited set of datasets. We also highlight different citing practices, making the automation of tracking difficult.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ml-1 p-2">Bibliometrics
</span><span class="btn badge btn-info ml-1 p-2">Datasets
</span><span class="btn badge btn-info ml-1 p-2">Medical Imaging
</span><span class="btn badge btn-info ml-1 p-2">Meta-analysis
</span><span class="btn badge btn-info ml-1 p-2">Open-Access tools</span></div><div class=details-btn><a class="btn btn-outline-info ml-1 pl-2 mb-2" href="https://openreview.net/forum?id=gFIepubv7E" target=_blank rel=noopener role=button>Details</a></div></div></div></div><div class="col-12 p-2 pub-filtr-item" data-category=pub-all,pub-machinelearning,pub-medical><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Detection Transformer for Teeth Detection, Segmentation, and Numbering in Oral Rare Diseases: Focus on Data Augmentation and Inpainting Techniques</h5><div class=sub-title><span><a href=https://american-cse.org/index.html/>The 2023 International Conference on Computational Science & Computational Intelligence (CSCI'23)</a></span>
<span class=ml-2>December 2023</span></div><div class=authors><span class=mr-2><a href>Kadi Hocine</a></span>
<span class=mr-2><a href=https://tsourget.fr>Théo Sourget</a></span>
<span class=mr-2><a href>Kawczynski Marzena</a></span>
<span class=mr-2><a href>Bendjama Sara</a></span>
<span class=mr-2><a href>Grollemund Bruno</a></span>
<span class=mr-2><a href>Bloch-Zupan Agnès</a></span></div></div><div class=card-body><p>In this work, we focused on deep learning image processing in the context of oral rare diseases, which pose challenges due to limited data availability. A crucial step involves teeth detection, segmentation and numbering in panoramic radiographs. To this end, we used a dataset consisting of 156 panoramic radiographs from individuals with rare oral diseases and labeled by experts. We trained the Detection Transformer (DETR) neural network for teeth detection, segmentation, and numbering the 52 teeth classes. In addition, we used data augmentation techniques, including geometric transformations. Finally, we generated new panoramic images using inpainting techniques with stable diffusion, by removing teeth from a panoramic radiograph and integrating teeth into it. The results showed a mAP exceeding 0,69 for DETR without data augmentation. The mAP was improved to 0,82 when data augmentation techniques are used. Furthermore, we observed promising performances when using new panoramic radiographs generated with inpainting technique, with mAP of 0,76.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ml-1 p-2">Instance Segmentation
</span><span class="btn badge btn-info ml-1 p-2">Data Generation
</span><span class="btn badge btn-info ml-1 p-2">Transformer</span></div><div class=details-btn><a class="btn btn-outline-info ml-1 pl-2 mb-2" href=https://arxiv.org/abs/2402.04408 target=_blank rel=noopener role=button>Details</a></div></div></div></div><div class="col-12 p-2 pub-filtr-item" data-category=pub-all,pub-machinelearning,pub-medical><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Can SegFormer be a True Competitor to U-Net for Medical Image Segmentation?</h5><div class=sub-title><span><a href=https://www.abdn.ac.uk/events/conferences/miua2023.php>27th Conference on Medical Image Understanding and Analysis (MIUA)</a></span>
<span class=ml-2>July 2023</span></div><div class=authors><span class=mr-2><a href=https://tsourget.fr>Théo Sourget</a></span>
<span class=mr-2><a href=https://www.linkedin.com/in/syed-nouman-hasany-b4648b100>Syed Nouman Hasany</a></span>
<span class=mr-2><a href=https://fr.linkedin.com/in/fabrice-meriaudeau-1aa2711a>Fabrice Mériaudeau</a></span>
<span class=mr-2><a href=https://fr.linkedin.com/in/caroline-petitjean-2922a42>Caroline Petitjean</a></span></div></div><div class=card-body><p>The U-Net model, introduced in 2015, is established as the state-of-the-art architecture for medical image segmentation, along with its variants UNet++, nnU-Net, V-Net, etc. Vision transformers made a breakthrough in the computer vision world in 2021. Since then, many transformer based architectures or hybrid architectures (combining convolutional blocks and transformer blocks) have been proposed for image segmentation, that are challenging the predominance of U-Net. In this paper, we ask the question whether transformers could overtake U-Net for medical image segmentation. We compare SegFormer, one of the most popular transformer architectures for segmentation, to U-Net using three publicly available medical image datasets that include various modalities and organs with the segmentation of cardiac structures in ultrasound images from the CAMUS challenge, the segmentation of polyp in endoscopy images and the segmentation of instrument in colonoscopy images from the MedAI challenge. We compare them in the light of various metrics (segmentation performance, training time) and show that SegFormer can be a true competitor to U-Net and should be carefully considered for future tasks in medical image segmentation.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ml-1 p-2">Segmentation
</span><span class="btn badge btn-info ml-1 p-2">CNN
</span><span class="btn badge btn-info ml-1 p-2">Transformer</span></div><div class=details-btn><a class="btn btn-outline-info ml-1 pl-2 mb-2" href=https://hal.science/hal-04161509/ target=_blank rel=noopener role=button>Details</a></div></div></div></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-white"><div class="container-fluid anchor pb-5 recent-posts-section"><h1 class=text-center><span id=recent-posts></span>Recent Posts</h1><div class=container><div class=row id=recent-post-cards><div class="col-lg-4 col-md-6 pt-2 post-card"><a href=/posts/my-research/citation-needed/ title="[Citation needed] Data usage and citation practices in medical imaging conferences​" class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/my-research/citation-needed/images/preview.png alt="Card image cap"></div><div class=card-body><h5 class=card-title>[Citation needed] Data usage and citation practices in medical imaging conferences​</h5><p class="card-text post-summary">Click on the image below to see my oral session at MIDL 2024:
Nowadays, the evaluation of models heavily relies on publicly available datasets used as benchmarking. While this could be a nice thing for a fair comparison of different models, we also question the effect of the diversity or more precisely a potential lack of diversity in research papers when selecting the datasets. A gap has been observed between the results showcased by AI models in research and their adoption in clinical workflow, we hypothesise that this gap could partly be a result of an overfitting of research on these datasets and we wanted to evaluate their usage to know if some are more popular than others.</p></div><div class=card-footer><span class=float-left>July 9, 2024</span>
<a href=/posts/my-research/citation-needed/ title=Read class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div></div></div></div></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/#about>About</a></li><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/#skills>Skills</a></li><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/#experiences>Experiences</a></li><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/#education>Education</a></li><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/#projects>Projects</a></li><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/#publications>Publications</a></li><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/#recent-posts>Recent Posts</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><a href=mailto:tsou@itu.dk target=_blank rel=noopener><span><i class="fas fa-envelope"></i></span> <span>tsou@itu.dk</span></a></li><li><a href=https://github.com/TheoSourget target=_blank rel=noopener><span><i class="fab fa-github"></i></span> <span>TheoSourget</span></a></li><li><a href=https://www.linkedin.com/in/theo-sourget target=_blank rel=noopener><span><i class="fab fa-linkedin"></i></span> <span>Théo Sourget</span></a></li></ul></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hugo-toha/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_3.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2020 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/application.b36454b05f709c04695fb0062b29988047346eb07b686cb61dc724087c1b29cf.js integrity="sha256-s2RUsF9wnARpX7AGKymYgEc0brB7aGy2HcckCHwbKc8=" defer></script></body></html>