# section information
section:
  name: Publications
  id: publications
  enable: true
  weight: 6
  showOnNavbar: true
  # Can optionally hide the title in sections
  # hideTitle: true

# filter buttons
# buttons:
# - name: All
#   filter: "all"
# - name: "Machine Learning"
#   filter: "machinelearning"
# - name: "Image Processing"
#   filter: "image-processing"

# your publications
publications:
- title: "In the Picture: Medical Imaging Datasets, Artifacts, and their Living Review"
  publishedIn:
    name: ACM FAccT 2025 
    date: June 2025
    url: https://facctconference.org/2025/
  authors:
  - name: Amelia Jiménez-Sánchez
    url: https://ameliajimenez.github.io/
  - name: Natalia-Rozalia Avlona
  - name: Sarah de Boer 
  - name: Víctor M. Campello
  - name: Aasa Feragen 
  - name: Enzo Ferrante
  - name: Melanie Ganz
  - name: Judy Wawira Gichoya
  - name: Camila González
  - name: Steff Groefsema 
  - name: Alessa Hering
  - name: Adam Hulman 
  - name: Leo Joskowicz
  - name: Dovile Juodelyte
    url: https://dk.linkedin.com/in/djuodelyte
  - name: Melih Kandemir
  - name: Thijs Kooi
  - name: Jorge del Pozo Lérida 
  - name: Livie Yumeng Li
  - name: Andre Pacheco 
  - name: Tim Rädsch
  - name: Mauricio Reyes
  - name: Théo Sourget
    url: https://tsourget.fr
  - name: Bram van Ginneken
  - name: David Wen 
  - name: Nina Weng
  - name: Jack Junchi Xu
    url: https://dk.linkedin.com/in/jack-junchi-xu-106909104 
  - name: Hubert Dariusz Zając
  - name: Maria A. Zuluaga  
  - name: Veronika Cheplygina
    url: https://veronikach.com/ 
  paper:
    summary: "Datasets play a critical role in medical imaging research, yet issues such as label quality, shortcuts, and metadata are often overlooked. This lack of attention may harm the generalizability of algorithms and, consequently, negatively impact patient outcomes. While existing medical imaging literature reviews mostly focus on machine learning (ML) methods, with only a few focusing on datasets for specific applications, these reviews remain static – they are published once and not updated thereafter. This fails to account for emerging evidence, such as biases, shortcuts, and additional annotations that other researchers may contribute after the dataset is published. We refer to these newly discovered findings of datasets as research artifacts. To address this gap, we propose a living review that continuously tracks public datasets and their associated research artifacts across multiple medical imaging applications. Our approach includes a framework for the living review to monitor data documentation artifacts, and an SQL database to visualize the citation relationships between research artifact and dataset. Lastly, we discuss key considerations for creating medical imaging datasets, review best practices for data annotation, discuss the significance of shortcuts and demographic diversity, and emphasize the importance of managing datasets throughout their entire lifecycle. Our demo is publicly available at http://inthepicture.itu.dk/."
    url: https://dl.acm.org/doi/10.1145/3715275.3732035
  categories: ["machinelearning","medical"]
  tags: ["Open data", "Data governance", "Healthcare", "Medical imaging","Shortcuts","Bias","Research artifacts","Living review"]

- title: "Mask of truth: model sensitivity to unexpected regions of medical images"
  publishedIn:
    name: Journal of Imaging Informatics in Medicine 
    date: May 2025
    url: https://link.springer.com/journal/10278
  authors:
  - name: Théo Sourget
    url: https://tsourget.fr
  - name: Michelle Hestbek-Møller
    url: 
  - name: Amelia Jiménez-Sánchez
    url: https://ameliajimenez.github.io/
  - name: Jack Junchi Xu
    url: https://dk.linkedin.com/in/jack-junchi-xu-106909104
  - name: Veronika Cheplygina
    url: https://veronikach.com/ 
  paper:
    summary: "The development of larger models for medical image analysis has led to increased performance. However, it also affected our ability to explain and validate model decisions. Models can use non-relevant parts of images, also called spurious correlations or shortcuts, to obtain high performance on benchmark datasets but fail in real-world scenarios. In this work, we challenge the capacity of convolutional neural networks (CNN) to classify chest X-rays and eye fundus images while masking out clinically relevant parts of the image. We show that all models trained on the PadChest dataset, irrespective of the masking strategy, are able to obtain an Area Under the Curve (AUC) above random. Moreover, the models trained on full images obtain good performance on images without the region of interest (ROI), even superior to the one obtained on images only containing the ROI. We also reveal a possible spurious correlation in the Chaksu dataset while the performances are more aligned with the expectation of an unbiased model. We go beyond the performance analysis with the usage of the explainability method SHAP and the analysis of embeddings. We asked a radiology resident to interpret chest X-rays under different masking to complement our findings with clinical knowledge."
    url: https://link.springer.com/article/10.1007/s10278-025-01531-5
  categories: ["machinelearning","medical"]
  tags: ["Shortcut learning", "Model robustness", "Chest X-ray classification","Glaucoma classification"]

- title: "Copycats: the many lives of a publicly available medical imaging dataset"
  publishedIn:
    name: NeurIPS 2024 Datasets and Benchmarks Track 
    date: December 2024
    url: https://neurips.cc/
  authors:
  - name: Amelia Jiménez-Sánchez
    url: https://ameliajimenez.github.io/
  - name: Natalia-Rozalia Avlona 
  - name: Dovile Juodelyte
    url: https://dk.linkedin.com/in/djuodelyte
  - name: Théo Sourget
    url: https://tsourget.fr
  - name: Caroline Vang-Larsen
  - name: Anna Rogers 
  - name: Hubert Dariusz Zajac
  - name: Veronika Cheplygina
    url: https://veronikach.com/
  paper:
    summary: "Medical Imaging (MI) datasets are fundamental to artificial intelligence in healthcare. The accuracy, robustness, and fairness of diagnostic algorithms depend on the data (and its quality) used to train and evaluate the models. MI datasets used to be proprietary, but have become increasingly available to the public, including on community-contributed platforms (CCPs) like Kaggle or HuggingFace. While open data is important to enhance the redistribution of data's public value, we find that the current CCP governance model fails to uphold the quality needed and recommended practices for sharing, documenting, and evaluating datasets. In this paper, we conduct an analysis of publicly available machine learning datasets on CCPs, discussing datasets' context, and identifying limitations and gaps in the current CCP landscape. We highlight differences between MI and computer vision datasets, particularly in the potentially harmful downstream effects from poor adoption of recommended dataset management practices. We compare the analyzed datasets across several dimensions, including data sharing, data documentation, and maintenance. We find vague licenses, lack of persistent identifiers and storage, duplicates, and missing metadata, with differences between the platforms. Our research contributes to efforts in responsible data curation and AI algorithms for healthcare."
    url: https://proceedings.neurips.cc/paper_files/paper/2024/hash/cdbeaeb8a0313940a5752c4ec8838ca6-Abstract-Datasets_and_Benchmarks_Track.html
  categories: ["machinelearning","medical"]
  tags: ["Open Data", "Medical Imaging", "Datasets", "Dataset Management","Data Governance"]

- title: "[Citation needed] Data usage and citation practices in medical imaging conferences"
  publishedIn:
    name: Medical Imaging with Deep Learning 2024 (MIDL'24)
    date: July 2024
    url: https://2024.midl.io/
  authors:
  - name: Théo Sourget
    url: https://tsourget.fr
  - name: Ahmet Akkoç 
  - name: Stinna Winther
  - name: Christine Lyngbye Galsgaard
  - name: Amelia Jiménez-Sánchez
    url: https://ameliajimenez.github.io/
  - name: Dovile Juodelyte
    url: https://dk.linkedin.com/in/djuodelyte
  - name: Caroline Petitjean
    url: https://fr.linkedin.com/in/caroline-petitjean-2922a42
  - name: Veronika Cheplygina
    url: https://veronikach.com/
  paper:
    summary: "Medical imaging papers often focus on methodology, but the quality of the algorithms and the validity of the conclusions are highly dependent on the datasets used. As creating datasets requires a lot of effort, researchers often use publicly available datasets, there is however no adopted standard for citing the datasets used in scientific papers, leading to difficulty in tracking dataset usage. In this work, we present two open-source tools we created that could help with the detection of dataset usage, a pipeline using OpenAlex and full-text analysis, and a PDF annotation software used in our study to manually label the presence of datasets. We applied both tools on a study of the usage of 20 publicly available medical datasets in papers from MICCAI and MIDL. We compute the proportion and the evolution between 2013 and 2023 of 3 types of presence in a paper: cited, mentioned in the full text, cited and mentioned. Our findings demonstrate the concentration of the usage of a limited set of datasets. We also highlight different citing practices, making the automation of tracking difficult."
    url: https://openreview.net/forum?id=gFIepubv7E
  categories: ["machinelearning","medical"]
  tags: ["Bibliometrics", "Datasets", "Medical Imaging", "Meta-analysis","Open-Access tools"]

- title: "Detection Transformer for Teeth Detection, Segmentation, and Numbering in Oral Rare Diseases: Focus on Data Augmentation and Inpainting Techniques"
  publishedIn:
    name: The 2023 International Conference on Computational Science & Computational Intelligence (CSCI'23)
    date: December 2023
    url: https://american-cse.org/index.html/
  authors:
  - name: Kadi Hocine 
  - name: Théo Sourget
    url: https://tsourget.fr
  - name: Kawczynski Marzena 
  - name: Bendjama Sara
  - name: Grollemund Bruno
  - name: Bloch-Zupan Agnès 
  paper:
    summary: In this work, we focused on deep learning image processing in the context of oral rare diseases, which pose challenges due to limited data availability. A crucial step involves teeth detection, segmentation and numbering in panoramic radiographs. To this end, we used a dataset consisting of 156 panoramic radiographs from individuals with rare oral diseases and labeled by experts. We trained the Detection Transformer (DETR) neural network for teeth detection, segmentation, and numbering the 52 teeth classes. In addition, we used data augmentation techniques, including geometric transformations. Finally, we generated new panoramic images using inpainting techniques with stable diffusion, by removing teeth from a panoramic radiograph and integrating teeth into it. The results showed a mAP exceeding 0,69 for DETR without data augmentation. The mAP was improved to 0,82 when data augmentation techniques are used. Furthermore, we observed promising performances when using new panoramic radiographs generated with inpainting technique, with mAP of 0,76. 
    url: https://arxiv.org/abs/2402.04408
  categories: ["machinelearning","medical"]
  tags: ["Instance Segmentation", "Data Generation", "Transformer"]

- title: Can SegFormer be a True Competitor to U-Net for Medical Image Segmentation?
  publishedIn:
    name: 27th Conference on Medical Image Understanding and Analysis (MIUA)
    date: July 2023
    url: https://www.abdn.ac.uk/events/conferences/miua2023.php
  authors:
  - name: Théo Sourget
    url: https://tsourget.fr
  - name: Syed Nouman Hasany 
    url: https://www.linkedin.com/in/syed-nouman-hasany-b4648b100
  - name: Fabrice Mériaudeau 
    url: https://fr.linkedin.com/in/fabrice-meriaudeau-1aa2711a
  - name: Caroline Petitjean 
    url: https://fr.linkedin.com/in/caroline-petitjean-2922a42
  paper:
    summary: The U-Net model, introduced in 2015, is established as the state-of-the-art architecture for medical image segmentation, along with its variants UNet++, nnU-Net, V-Net, etc. Vision transformers made a breakthrough in the computer vision world in 2021. Since then, many transformer based architectures or hybrid architectures (combining convolutional blocks and transformer blocks) have been proposed for image segmentation, that are challenging the predominance of U-Net. In this paper, we ask the question whether transformers could overtake U-Net for medical image segmentation. We compare SegFormer, one of the most popular transformer architectures for segmentation, to U-Net using three publicly available medical image datasets that include various modalities and organs with the segmentation of cardiac structures in ultrasound images from the CAMUS challenge, the segmentation of polyp in endoscopy images and the segmentation of instrument in colonoscopy images from the MedAI challenge. We compare them in the light of various metrics (segmentation performance, training time) and show that SegFormer can be a true competitor to U-Net and should be carefully considered for future tasks in medical image segmentation. 
    url: https://link.springer.com/chapter/10.1007/978-3-031-48593-0_8
  categories: ["machinelearning","medical"]
  tags: ["Segmentation", "CNN", "Transformer"]


