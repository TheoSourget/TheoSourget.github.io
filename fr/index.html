<!doctype html><html lang=fr><head><meta name=generator content="Hugo 0.147.9"><title>Theo Sourget</title><meta name=description content="Portfolio and personal blog of John Doe."><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=stylesheet href=/application.228e9114d0768fdf2ebe316bcc9c20f3a463a83871918d61b1482f8de98636dd.css integrity="sha256-Io6RFNB2j98uvjFrzJwg86RjqDhxkY1hsUgvjemGNt0="><link rel=icon type=image/png href=/images/site/favicon_hu_c990906e455bc973.png><link rel=alternate type=application/rss+xml href=https://theosourget.github.io/fr/index.xml title="Theo Sourget"><meta property="og:title" content="Théo Sourget"><meta property="og:type" content="website"><meta property="og:description" content="Site personnel de Théo Sourget."><meta property="og:image" content="/images/author/theo_sourget.jpg"><meta property="og:url" content="https://hugo-toha.github.io"><script integrity="sha256-DO4ugzEwhTW1Id1UIWn0gUJWaebCYOypeTit6LW4QB4=">let theme=localStorage.getItem("theme-scheme")||localStorage.getItem("darkmode:color-scheme")||"light";theme==="system"&&(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?theme="dark":theme="light"),document.documentElement.setAttribute("data-theme",theme)</script></head><body data-bs-spy=scroll data-bs-target=#top-navbar data-bs-offset=100><nav class="navbar navbar-expand-xl top-navbar shadow transparent-navbar homepage" id=top-navbar><div class=container><a class=navbar-brand href=/fr><img src=/images/site/inverted-logo_hu_c990906e455bc973.png id=logo alt=Logo>
Theo Sourget</a>
<button class="navbar-toggler navbar-dark" id=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#top-nav-items aria-label=menu>
<i data-feather=menu></i></button><div class="collapse navbar-collapse dynamic-navbar" id=top-nav-items><ul class="nav navbar-nav ms-auto"><li class=nav-item><a class=nav-link href=#home>Accueil</a></li><li class=nav-item><a class=nav-link href=#about>Présentation</a></li><li class=nav-item><a class=nav-link href=#skills>Compétences</a></li><li class=nav-item><a class=nav-link href=#experiences>Expérience professionnelle</a></li><li class=nav-item><a class=nav-link href=#education>Diplômes</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>Suite</a><div class=dropdown-menu aria-labelledby=navbarDropdown><a class=dropdown-item href=#projects>Projets</a>
<a class=dropdown-item href=#publications>Publications</a>
<a class=dropdown-item href=#recent-posts>Poste récents</a></div></li><div id=top-navbar-divider></div><li class=nav-item><a class=nav-link id=blog-link href=/fr/posts>Articles</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=languageSelector role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false><span class="fi fi-fr"></span>
Français</a><div class=dropdown-menu aria-labelledby=languageSelector><a class="dropdown-item nav-link languages-item" href=/><span class="fi fi-gb"></span>
English
</a><a class="dropdown-item nav-link languages-item" href=/fr><span class="fi fi-fr"></span>
Français</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg class=theme-icon src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme"></a><div id=themeMenu class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# data-scheme=light><img class=theme-icon src=/icons/sun-svgrepo-com.svg width=20 alt="Light Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=dark><img class=theme-icon src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=system><img class=theme-icon src=/icons/computer-svgrepo-com.svg width=20 alt="System Theme"></a></div></li></ul></div></div><img src=/images/site/main-logo_hu_1911791e11ae947a.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu_c990906e455bc973.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><div class="container-fluid home" id=home><style>#homePageBackgroundImageDivStyled{background-image:url(/images/site/background_hu_27fa8d5953636a0d.jpg)}@media(min-width:500px) and (max-width:800px){#homePageBackgroundImageDivStyled{background-image:url(/images/site/background_hu_fef63e308c1d35f0.jpg)}}@media(min-width:801px) and (max-width:1200px){#homePageBackgroundImageDivStyled{background-image:url(/images/site/background_hu_c480fb4fa3fe9078.jpg)}}@media(min-width:1201px) and (max-width:1500px){#homePageBackgroundImageDivStyled{background-image:url(/images/site/background_hu_9482880f4beea8da.jpg)}}@media(min-width:1501px){#homePageBackgroundImageDivStyled{background-image:url(/images/site/background.jpg)}}html[data-theme=dark]{ #homePageBackgroundImageDivStyled { background-image: url('/images/site/background_hu_27fa8d5953636a0d.jpg'); } @media (min-width: 500px) and (max-width: 800px) { #homePageBackgroundImageDivStyled { background-image: url('/images/site/background_hu_fef63e308c1d35f0.jpg'); } } @media (min-width: 801px) and (max-width: 1200px) { #homePageBackgroundImageDivStyled { background-image: url('/images/site/background_hu_c480fb4fa3fe9078.jpg'); } } @media (min-width: 1201px) and (max-width: 1500px) { #homePageBackgroundImageDivStyled { background-image: url('/images/site/background_hu_9482880f4beea8da.jpg'); } } @media (min-width: 1501px) { #homePageBackgroundImageDivStyled { background-image: url('/images/site/background.jpg'); } }}</style><span class=on-the-fly-behavior></span><div id=homePageBackgroundImageDivStyled class="background container-fluid"></div><div class="container content text-center"><img src=/images/author/theo_s_hu_d963bc6f6b0d1d15.jpeg class="rounded-circle mx-auto d-block img-fluid" alt="Author Image"><h1 class=greeting>Bonjour, je suis Théo Sourget</h1><div class=typing-carousel><span id=ityped class=ityped></span>
<span class=ityped-cursor></span></div><ul id=typing-carousel-data><li>Je suis un Data Scientist</li><li>Je suis un Assistant Recherche</li><li>Je suis intéressé par l'analyse d'imagerie médicale</li></ul><a href=#about class=arrow-center aria-label="Lire Suite - Théo Sourget"><i class="arrow bounce fa fa-chevron-down"></i></a></div></div><div class="container-fluid section-holder d-flex bg-primary"><div class="container anchor p-lg-5 about-section" id=about><div class="row pt-sm-2 pt-md-4 align-self-center"><div class=col-sm-12><h3 class=p-1>Théo Sourget</h3><h5 class=p-1>Ingénieur d'étude
chez <a href=https://mics.centralesupelec.fr/ title="CentraleSupélec - MICS." target=_blank rel=noopener>CentraleSupélec - MICS.</a></h5><p class="p-1 text-justify">Passionné par la Data Science et l&rsquo;IA, j&rsquo;ai obtenu en 2023 mon diplôme de Master à <a href=http://mastersid.univ-rouen.fr/en/index.php target=_blank rel=noopener>l&rsquo;Université de Rouen</a>. Durant mes études, je me suis spécialisée dans l&rsquo;analyse d&rsquo;images médicales avec des projets portant sur la classification et la segmentation d&rsquo;images médicales à l&rsquo;aide de modèles de deep learning. Ces projets portaient également sur l&rsquo;entraînement de modèles transformers avec des datasets de tailles limitées ainsi que sur l&rsquo;effet de l&rsquo;augmentation des données et du transfer learning.</p><div class="text-container ms-auto"><ul class="social-link d-flex"><li><a href=https://github.com/TheoSourget title=Github target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/theo-sourget/ title=LinkedIn target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=mailto:tsou@itu.dk title=Email target=_blank rel=noopener><i class="fas fa-envelope"></i></a></li></ul></div><a href=/files/resume.pdf title="Mon CV" target=#><button class="btn btn-dark">Mon CV</button></a></div><div class="col-sm-6 pt-5 ps-md-4 ps-sm-3 pt-sm-0"><div class=row></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-secondary"><div class="container-fluid anchor pb-5 skills-section" id=skills><h1 class=text-center><span id=skills></span>Compétences</h1><div class="container d-flex-block"><div class=row id=primary-skills><div class="col-xs-12 col-sm-6 col-lg-4 pt-2 filtr-item" data-category='all, '><a class=text-decoration-none><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/python_hu_12b55e8e84f05a81.png alt=Python><h5 class=card-title>Python</h5></div><div class="card-body text-justify pt-1 pb-1"><p class=card-text>Python est le langage avec lequel je code le plus. J&rsquo;ai utilisé de nombreuses bibliothèques pour la data science telles que PyTorch, Pandas, Scikit-Learn et Numpy.</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2 filtr-item" data-category='all, '><a class=text-decoration-none><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/streamlit.svg alt=Streamlit><h5 class=card-title>Streamlit</h5></div><div class="card-body text-justify pt-1 pb-1"><p class=card-text>J&rsquo;ai régulièrement utilisé streamlit afin de construire des sites de démonstration sur le travail effectué</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2 filtr-item" data-category='all, '><a class=text-decoration-none><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/api_hu_8c681fdbeedc42d9.png alt=API><h5 class=card-title>API</h5></div><div class="card-body text-justify pt-1 pb-1"><p class=card-text>J&rsquo;ai utilisé et créé des API dans le cadre de nombreux projets</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2 filtr-item" data-category='all, '><a class=text-decoration-none><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/docker.svg alt=Docker><h5 class=card-title>Docker</h5></div><div class="card-body text-justify pt-1 pb-1"><p class=card-text>J&rsquo;ai souvent utilisé Docker avec Streamlit et FastAPI pour faciliter le déploiement de mes outils</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2 filtr-item" data-category='all, '><a class=text-decoration-none><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/linux_hu_1dbc6391c584bd2f.png alt=Linux><h5 class=card-title>Linux</h5></div><div class="card-body text-justify pt-1 pb-1"><p class=card-text>Mon OS principal depuis 3 ans</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2 filtr-item" data-category='all, '><a class=text-decoration-none><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/git_hu_15d77950cb79075d.png alt=Git><h5 class=card-title>Git</h5></div><div class="card-body text-justify pt-1 pb-1"><p class=card-text>J&rsquo;ai de l&rsquo;expérience dans le développement avec git. J&rsquo;ai utilisé à la fois Github et Gitlab.</p></div></div></a></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-primary"><div class="container-fluid anchor pb-5 experiences-section"><h1 class=text-center><span id=experiences></span>Expérience professionnelle</h1><div class="container timeline text-justify"><div class="row align-items-center d-flex"><div class="col-1 col-lg-2 text-center vertical-line d-inline-flex justify-content-center"><div class="circle fw-bold">1</div></div><div class="col-10 col-lg-8"><div class=experience-entry-heading><div class=company-heading><h5><a href=https://mics.centralesupelec.fr/ title="CentraleSupélec - MICS" target=_blank rel=noopener>CentraleSupélec - MICS</a></h5><p class=text-muted>April 2025 - Current</p></div><p class=text-muted><i class="fa-solid fa-location-dot"></i> Gif-sur-Yvette (France)</p><p></p></div><div class=positions><div class=company-heading><h5 class=designation>Research Engineer</h5><p class=text-muted>April 2025 - Current</p></div><h6 class=text-heading>Responsabilités :</h6><ul class=justify-content-around><li>I study biases in Vision-Language model</li></ul></div></div></div><div class="row horizontal-line"><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div><div class="col-10 col-lg-8"><hr></div><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div></div><div class="row align-items-center justify-content-end d-flex"><div class="col-10 col-lg-8"><div class=experience-entry-heading><div class=company-heading><h5><a href=https://purrlab.github.io/ title="IT University of Copenhagen - PURRlab" target=_blank rel=noopener>IT University of Copenhagen - PURRlab</a></h5><p class=text-muted>October 2023 - Aujourd'hui</p></div><p class=text-muted><i class="fa-solid fa-location-dot"></i> Copenhagen (Denmark)</p><p></p></div><div class=positions><div class=company-heading><h5 class=designation>Research Assistant</h5><p class=text-muted>October 2023 - Aujourd'hui</p></div><h6 class=text-heading>Responsabilités :</h6><ul class=justify-content-around><li>Study how public medical image datasets are referenced in research papers</li></ul><div class=company-heading><h5 class=designation>Teaching Assistant</h5><p class=text-muted>October 2023 - Aujourd'hui</p></div><h6 class=text-heading>Responsabilités :</h6><ul class=justify-content-around><li>Help students during practical work</li></ul></div></div><div class="col-1 col-lg-2 text-center vertical-line d-inline-flex justify-content-center"><div class="circle fw-bold">2</div></div></div><div class="row horizontal-line"><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div><div class="col-10 col-lg-8"><hr></div><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div></div><div class="row align-items-center d-flex"><div class="col-1 col-lg-2 text-center vertical-line d-inline-flex justify-content-center"><div class="circle fw-bold">3</div></div><div class="col-10 col-lg-8"><div class=experience-entry-heading><div class=company-heading><h5><a href=https://www.capgemini.com/us-en/about-us/who-we-are/our-brands/capgemini-engineering/ title="Capgemini Engineering - Medic@" target=_blank rel=noopener>Capgemini Engineering - Medic@</a></h5><p class=text-muted>April 2023 - September 2023</p></div><p class=text-muted><i class="fa-solid fa-location-dot"></i> Illkirch-Graffenstaden (France)</p><p></p></div><div class=positions><div class=company-heading><h5 class=designation>Data scientist intern</h5><p class=text-muted>April 2023 - September 2023</p></div><h6 class=text-heading>Responsabilités :</h6><ul class=justify-content-around><li>Detection, segmentation and numbering of teeth in dental panoramic x-ray.</li><li>Comparison of Mask-RCNN and Detection Transformer (DETR).</li><li>Comparison of &ldquo;classical&rdquo; data augmentation technics with augmentation using the generation of new panoramics.</li></ul></div></div></div><div class="row horizontal-line"><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div><div class="col-10 col-lg-8"><hr></div><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div></div><div class="row align-items-center justify-content-end d-flex"><div class="col-10 col-lg-8"><div class=experience-entry-heading><div class=company-heading><h5><a href=https://see-d.fr/ title=See-d target=_blank rel=noopener>See-d</a></h5><p class=text-muted>April 2021 - July 2021</p></div><p class=text-muted><i class="fa-solid fa-location-dot"></i> Vannes (France)</p><p></p></div><div class=positions><div class=company-heading><h5 class=designation>Developer</h5><p class=text-muted>June 2021 - July 2021</p></div><h6 class=text-heading>Responsabilités :</h6><ul class=justify-content-around><li>Continuation of the intership</li><li>Creation of a dashboard with Qlik Sense using the previously created API</li></ul><div class=company-heading><h5 class=designation>Developer Intern</h5><p class=text-muted>April 2021 - June 2021</p></div><h6 class=text-heading>Responsabilités :</h6><ul class=justify-content-around><li>Development of a storage-related data analysis website with Python and Streamlit</li><li>Deployement with Docker</li><li>Presentation of the tool to the team</li></ul></div></div><div class="col-1 col-lg-2 text-center vertical-line d-inline-flex justify-content-center"><div class="circle fw-bold">4</div></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-secondary"><div class="container-fluid anchor pb-5 education-section"><h1 class=text-center><span id=education></span>Diplômes</h1><div class=container><table class=education-info-table><tbody><tr><td class=icon><div class=hline></div><div class=icon-holder><i class="fas fa-graduation-cap"></i></div></td><td class=line><div></div></td><td class=details><div class="degree-info card"><div class=row><div class="col-lg-10 col-md-8"><h5><a href=http://mastersid.univ-rouen.fr/en/index.php title="Université de Rouen" target=_blank rel=noopener>Université de Rouen</a></h5></div><div class="timeframe col-lg-2 col-md-4">2021-2023</div></div><h6>Master Data Science and Engineering (SID)</h6><h6><span class=text-heading>Grade: </span><span>16.215</span> sur <span>20 (Graduated with Highest Honors)</span></h6></div></td></tr><tr><td class=icon><div class=hline></div><div class=icon-holder><i class="fas fa-university"></i></div></td><td class=line><div></div></td><td class=details><div class="degree-info card"><div class=row><div class="col-lg-10 col-md-8"><h5>Université de Rouen</h5></div><div class="timeframe col-lg-2 col-md-4">2020-2021</div></div><h6>Bachelor's degree in Computer Science and Data Science</h6><h6><span class=text-heading>Grade: </span><span>14.958</span> sur <span>20 (Graduated with Honors)</span></h6></div></td></tr><tr><td class=icon><div class=hline></div><div class=icon-holder><i class="fas fa-university"></i></div></td><td class=line><div></div></td><td class=details><div class="degree-info card"><div class=row><div class="col-lg-10 col-md-8"><h5>IUT de Vannes</h5></div><div class="timeframe col-lg-2 col-md-4">2018-2020</div></div><h6>2 years diploma in Computer science</h6><h6><span class=text-heading>Grade: </span><span>13.835</span> sur <span>20</span></h6></div></td></tr></tbody></table></div></div></div><div class="container-fluid section-holder d-flex bg-primary"><div class="container-fluid anchor pb-5 projects-section" id=projects><h1 class=text-center><span id=projects></span>Projets</h1><div class="container ms-auto text-center"><div class="btn-group flex-wrap" role=group id=project-filter-buttons><button type=button class="btn btn-dark project-filtr-control" data-filter=all>
All
</button>
<button type=button class="btn btn-dark project-filtr-control" data-filter="Medical Image Analysis">
Medical Image Analysis
</button>
<button type=button class="btn btn-dark project-filtr-control" data-filter=Sport>
Sport
</button>
<button type=button class="btn btn-dark project-filtr-control" data-filter=Web>
Web</button></div></div><div class="container filtr-projects"><div class=row id=project-card-holder><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Web,API,Streamlit,FastAPI,Docker'><div class="card mt-1"><div class=card><a href=https://github.com/TheoSourget/citation_finder target=_blank rel=noopener><div class=card-header><div><div class=d-flex><h5 class="card-title mb-0">Citation finder</h5></div><div class=sub-title><span></span>
<span>2023</span></div></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Website multiple API such as OpenAlex to search for papers referencing another one and papers matching keywords and concept.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Web
</span><span class="badge btn-info">API
</span><span class="badge btn-info">Streamlit
</span><span class="badge btn-info">FastAPI
</span><span class="badge btn-info">Docker</span></div><div class=project-btn-holder><a class="github-button project-btn d-none" href=https://github.com/TheoSourget/citation_finder data-icon=octicon-standard data-show-count=true aria-label="Star Citation finder">Star</a></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Medical Image Analysis,Segmentation,Transformer,Pytorch'><div class="card mt-1"><div class=card><a href=https://github.com/TheoSourget/SegFormer_CAMUS target=_blank rel=noopener><div class=card-header><div><div class=d-flex><h5 class="card-title mb-0">Research project Master 2</h5></div><div class=sub-title><span></span>
<span>2022 - 2023</span></div></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Comparison of Segformer and U-Net to perform semantic segmentation on the CAMUS dataset (cardiac ultrasound images).</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Medical Image Analysis
</span><span class="badge btn-info">Segmentation
</span><span class="badge btn-info">Transformer
</span><span class="badge btn-info">Pytorch</span></div><div class=project-btn-holder><a class="github-button project-btn d-none" href=https://github.com/TheoSourget/SegFormer_CAMUS data-icon=octicon-standard data-show-count=true aria-label="Star Research project Master 2">Star</a></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Medical Image Analysis,Classification,Tensorflow,CNN'><div class="card mt-1"><div class=card><a href=javascript:void(0)><div class=card-header><div><div class=d-flex><h5 class="card-title mb-0">Research project Master 1</h5></div><div class=sub-title><span></span>
<span>2021 - 2022</span></div></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Classification of eye fundus images for glaucoma detection with convolutional neural network.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Medical Image Analysis
</span><span class="badge btn-info">Classification
</span><span class="badge btn-info">Tensorflow
</span><span class="badge btn-info">CNN</span></div><div class=project-btn-holder></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Data Analysis,Sport,Matplotlib,Pandas'><div class="card mt-1"><div class=card><a href=javascript:void(0)><div class=card-header><div><div class=d-flex><h5 class="card-title mb-0">Bachelor's degree project</h5></div><div class=sub-title><span></span>
<span>2020 - 2021</span></div></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Analysis of a dataset on the 2011-2012 season of the Premier League.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Data Analysis
</span><span class="badge btn-info">Sport
</span><span class="badge btn-info">Matplotlib
</span><span class="badge btn-info">Pandas</span></div><div class=project-btn-holder></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Web,React,Flask,MongoDB'><div class="card mt-1"><div class=card><a href=javascript:void(0)><div class=card-header><div><div class=d-flex><h5 class="card-title mb-0">Astronomical observation website</h5></div><div class=sub-title><span></span>
<span>2020</span></div></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Development of an astronomical observation website with React-Flask-MongoDB.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Web
</span><span class="badge btn-info">React
</span><span class="badge btn-info">Flask
</span><span class="badge btn-info">MongoDB</span></div><div class=project-btn-holder></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, Web,Mobile,Sport,React,MERN stack'><div class="card mt-1"><div class=card><a href=javascript:void(0)><div class=card-header><div><div class=d-flex><h5 class="card-title mb-0">Applicharge</h5></div><div class=sub-title><span></span>
<span>2019-2020</span></div></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Development of a website and a mobile application for sports management with React/React Native.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">Web
</span><span class="badge btn-info">Mobile
</span><span class="badge btn-info">Sport
</span><span class="badge btn-info">React
</span><span class="badge btn-info">MERN stack</span></div><div class=project-btn-holder></div></div></div></div></div></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-secondary"><div class="container-fluid anchor pb-5 publications-section" id=publications><h1 class=text-center><span id=publications></span>Publications</h1><div class="container ms-auto text-center"><div class="btn-group flex-wrap" role=pub-group id=publication-filter-buttons></div></div><div class="container filtr-publications"><div class=row id=publication-card-holder><div class="col-12 p-2 pub-filtr-item" data-category=pub-all,pub-machinelearning,pub-medical><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Copycats: the many lives of a publicly available medical imaging dataset</h5><div class=sub-title><span><a href=https://neurips.cc/>NeurIPS 2024 Datasets and Benchmarks Track</a>
</span><span class=ms-2>December 2024</span></div><div class=authors><span class=me-2><a>Amelia Jiménez-Sánchez</a></span>
<span class=me-2><a>Natalia-Rozalia Avlona</a></span>
<span class=me-2><a>Dovile Juodelyte</a></span>
<span class=me-2><a>Théo Sourget</a></span>
<span class=me-2><a>Caroline Vang-Larsen</a></span>
<span class=me-2><a>Anna Rogers</a></span>
<span class=me-2><a>Hubert Dariusz Zajac</a></span>
<span class=me-2><a>Veronika Cheplygina</a></span></div></div><div class=card-body><p>Medical Imaging (MI) datasets are fundamental to artificial intelligence in healthcare. The accuracy, robustness, and fairness of diagnostic algorithms depend on the data (and its quality) used to train and evaluate the models. MI datasets used to be proprietary, but have become increasingly available to the public, including on community-contributed platforms (CCPs) like Kaggle or HuggingFace. While open data is important to enhance the redistribution of data&rsquo;s public value, we find that the current CCP governance model fails to uphold the quality needed and recommended practices for sharing, documenting, and evaluating datasets. In this paper, we conduct an analysis of publicly available machine learning datasets on CCPs, discussing datasets&rsquo; context, and identifying limitations and gaps in the current CCP landscape. We highlight differences between MI and computer vision datasets, particularly in the potentially harmful downstream effects from poor adoption of recommended dataset management practices. We compare the analyzed datasets across several dimensions, including data sharing, data documentation, and maintenance. We find vague licenses, lack of persistent identifiers and storage, duplicates, and missing metadata, with differences between the platforms. Our research contributes to efforts in responsible data curation and AI algorithms for healthcare.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ms-1 p-2">Open Data
</span><span class="btn badge btn-info ms-1 p-2">Medical Imaging
</span><span class="btn badge btn-info ms-1 p-2">Datasets
</span><span class="btn badge btn-info ms-1 p-2">Dataset Management
</span><span class="btn badge btn-info ms-1 p-2">Data Governance</span></div><div class=details-btn><a class="btn btn-outline-info ms-1 ps-2 mb-2" href=https://arxiv.org/abs/2402.06353 target=_blank rel=noopener role=button>Détails</a></div></div></div></div><div class="col-12 p-2 pub-filtr-item" data-category=pub-all,pub-machinelearning,pub-medical><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">[Citation needed] Data usage and citation practices in medical imaging conferences</h5><div class=sub-title><span><a href=https://2024.midl.io/>Medical Imaging with Deep Learning 2024 (MIDL'24)</a>
</span><span class=ms-2>July 2024</span></div><div class=authors><span class=me-2><a href=https://tsourget.fr>Théo Sourget</a></span>
<span class=me-2><a>Ahmet Akkoç</a></span>
<span class=me-2><a>Stinna Winther</a></span>
<span class=me-2><a>Christine Lyngbye Galsgaard</a></span>
<span class=me-2><a>Amelia Jiménez-Sánchez</a></span>
<span class=me-2><a>Dovile Juodelyte</a></span>
<span class=me-2><a>Caroline Petitjean</a></span>
<span class=me-2><a>Veronika Cheplygina</a></span></div></div><div class=card-body><p>Medical imaging papers often focus on methodology, but the quality of the algorithms and the validity of the conclusions are highly dependent on the datasets used. As creating datasets requires a lot of effort, researchers often use publicly available datasets, there is however no adopted standard for citing the datasets used in scientific papers, leading to difficulty in tracking dataset usage. In this work, we present two open-source tools we created that could help with the detection of dataset usage, a pipeline using OpenAlex and full-text analysis, and a PDF annotation software used in our study to manually label the presence of datasets. We applied both tools on a study of the usage of 20 publicly available medical datasets in papers from MICCAI and MIDL. We compute the proportion and the evolution between 2013 and 2023 of 3 types of presence in a paper: cited, mentioned in the full text, cited and mentioned. Our findings demonstrate the concentration of the usage of a limited set of datasets. We also highlight different citing practices, making the automation of tracking difficult.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ms-1 p-2">Bibliometrics
</span><span class="btn badge btn-info ms-1 p-2">Datasets
</span><span class="btn badge btn-info ms-1 p-2">Medical Imaging
</span><span class="btn badge btn-info ms-1 p-2">Meta-analysis
</span><span class="btn badge btn-info ms-1 p-2">Open-Access tools</span></div><div class=details-btn><a class="btn btn-outline-info ms-1 ps-2 mb-2" href="https://openreview.net/forum?id=gFIepubv7E" target=_blank rel=noopener role=button>Détails</a></div></div></div></div><div class="col-12 p-2 pub-filtr-item" data-category=pub-all,pub-machinelearning,pub-medical><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Detection Transformer for Teeth Detection, Segmentation, and Numbering in Oral Rare Diseases: Focus on Data Augmentation and Inpainting Techniques</h5><div class=sub-title><span><a href=https://american-cse.org/index.html/>The 2023 International Conference on Computational Science & Computational Intelligence (CSCI'23)</a>
</span><span class=ms-2>December 2023</span></div><div class=authors><span class=me-2><a>Kadi Hocine</a></span>
<span class=me-2><a href=https://tsourget.fr>Théo Sourget</a></span>
<span class=me-2><a>Kawczynski Marzena</a></span>
<span class=me-2><a>Bendjama Sara</a></span>
<span class=me-2><a>Grollemund Bruno</a></span>
<span class=me-2><a>Bloch-Zupan Agnès</a></span></div></div><div class=card-body><p>In this work, we focused on deep learning image processing in the context of oral rare diseases, which pose challenges due to limited data availability. A crucial step involves teeth detection, segmentation and numbering in panoramic radiographs. To this end, we used a dataset consisting of 156 panoramic radiographs from individuals with rare oral diseases and labeled by experts. We trained the Detection Transformer (DETR) neural network for teeth detection, segmentation, and numbering the 52 teeth classes. In addition, we used data augmentation techniques, including geometric transformations. Finally, we generated new panoramic images using inpainting techniques with stable diffusion, by removing teeth from a panoramic radiograph and integrating teeth into it. The results showed a mAP exceeding 0,69 for DETR without data augmentation. The mAP was improved to 0,82 when data augmentation techniques are used. Furthermore, we observed promising performances when using new panoramic radiographs generated with inpainting technique, with mAP of 0,76.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ms-1 p-2">Instance Segmentation
</span><span class="btn badge btn-info ms-1 p-2">Data Generation
</span><span class="btn badge btn-info ms-1 p-2">Transformer</span></div><div class=details-btn><a class="btn btn-outline-info ms-1 ps-2 mb-2" href=https://arxiv.org/abs/2402.04408 target=_blank rel=noopener role=button>Détails</a></div></div></div></div><div class="col-12 p-2 pub-filtr-item" data-category=pub-all,pub-machinelearning,pub-medical><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Can SegFormer be a True Competitor to U-Net for Medical Image Segmentation?</h5><div class=sub-title><span><a href=https://www.abdn.ac.uk/events/conferences/miua2023.php>27th Conference on Medical Image Understanding and Analysis (MIUA)</a>
</span><span class=ms-2>July 2023</span></div><div class=authors><span class=me-2><a href=https://tsourget.fr>Théo Sourget</a></span>
<span class=me-2><a href=https://www.linkedin.com/in/syed-nouman-hasany-b4648b100>Syed Nouman Hasany</a></span>
<span class=me-2><a href=https://fr.linkedin.com/in/fabrice-meriaudeau-1aa2711a>Fabrice Mériaudeau</a></span>
<span class=me-2><a href=https://fr.linkedin.com/in/caroline-petitjean-2922a42>Caroline Petitjean</a></span></div></div><div class=card-body><p>The U-Net model, introduced in 2015, is established as the state-of-the-art architecture for medical image segmentation, along with its variants UNet++, nnU-Net, V-Net, etc. Vision transformers made a breakthrough in the computer vision world in 2021. Since then, many transformer based architectures or hybrid architectures (combining convolutional blocks and transformer blocks) have been proposed for image segmentation, that are challenging the predominance of U-Net. In this paper, we ask the question whether transformers could overtake U-Net for medical image segmentation. We compare SegFormer, one of the most popular transformer architectures for segmentation, to U-Net using three publicly available medical image datasets that include various modalities and organs with the segmentation of cardiac structures in ultrasound images from the CAMUS challenge, the segmentation of polyp in endoscopy images and the segmentation of instrument in colonoscopy images from the MedAI challenge. We compare them in the light of various metrics (segmentation performance, training time) and show that SegFormer can be a true competitor to U-Net and should be carefully considered for future tasks in medical image segmentation.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ms-1 p-2">Segmentation
</span><span class="btn badge btn-info ms-1 p-2">CNN
</span><span class="btn badge btn-info ms-1 p-2">Transformer</span></div><div class=details-btn><a class="btn btn-outline-info ms-1 ps-2 mb-2" href=https://hal.science/hal-04161509/ target=_blank rel=noopener role=button>Détails</a></div></div></div></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-primary"><div class="container-fluid anchor pb-5 recent-posts-section"><h1 class=text-center><span id=recent-posts></span>Poste récents</h1><div class=container><div class=row id=recent-post-cards></div></div></div></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-start"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/fr/#about>Présentation</a></li><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/fr/#skills>Compétences</a></li><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/fr/#experiences>Expérience professionnelle</a></li><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/fr/#education>Diplômes</a></li><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/fr/#projects>Projets</a></li><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/fr/#publications>Publications</a></li><li class=nav-item><a class=smooth-scroll href=https://theosourget.github.io/fr/#recent-posts>Poste récents</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contactez moi :</h5><ul><li><a href=mailto:tsou@itu.df target=_blank rel=noopener><span><i class="fas fa-envelope"></i></span> <span>tsou@itu.df</span></a></li><li><a href=https://github.com/TheoSourget target=_blank rel=noopener><span><i class="fab fa-github"></i></span> <span>TheoSourget</span></a></li><li><a href=https://www.linkedin.com/in/theo-sourget target=_blank rel=noopener><span><i class="fab fa-linkedin"></i></span> <span>Théo Sourget</span></a></li></ul></div></div></div><hr><div class=container><div class="row text-start"><div class=col-md-4><a id=theme href=https://github.com/hugo-toha/toha target=_blank rel=noopener><img src=/images/theme-logo_hu_b3360284c55cf72d.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2020 Copyright.</div><div class="col-md-4 text-end"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Alimenté par
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/application.f6959e0d840b2a0cb8ebdc7b64f82c76ed540bafda2e2f31ece1d91e812ba4d1.js integrity="sha256-9pWeDYQLKgy469x7ZPgsdu1UC6/aLi8x7OHZHoErpNE=" defer></script></body></html>